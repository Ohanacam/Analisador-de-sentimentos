import streamlit as st
import joblib
import pickle
import os
import pandas as pd
import unidecode
import string
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer

# Configura√ß√£o inicial robusta do NLTK
def setup_nltk():
    try:
        nltk.data.find('tokenizers/punkt')
        nltk.data.find('corpora/stopwords')
    except LookupError:
        try:
            nltk.download('punkt')
            nltk.download('stopwords')
            nltk.download('punkt_tab')
        except Exception as e:
            st.error(f"Erro ao baixar recursos do NLTK: {str(e)}")
            return False
    return True

if not setup_nltk():
    st.error("N√£o foi poss√≠vel configurar o NLTK. O app n√£o pode continuar.")
    st.stop()

# Fun√ß√£o de pr√©-processamento segura
def preprocess_text(text):
    try:
        puncts = list(string.punctuation)
        stopwords_pt = stopwords.words("portuguese")
        adicionais = ["...", "..", "etc", "diz", "ficou", "app", "aplicativo"]
        stopwords_puncts = list(set(stopwords_pt + puncts + adicionais))
        
        text = unidecode.unidecode(text.lower())
        tokens = nltk.word_tokenize(text, language='portuguese')
        tokens = [word for word in tokens if word not in stopwords_puncts]
        return " ".join(tokens)
    except Exception as e:
        st.error(f"Erro no pr√©-processamento: {str(e)}")
        return ""

# Carregamento seguro do vetorizador com verifica√ß√£o
@st.cache_resource
def load_vectorizer():
    try:
        # Tenta carregar com joblib
        vectorizer = joblib.load('vectorizer_thirdanalysis_new.pkl')
        
        # Verifica se o vetorizador est√° fitted
        if not hasattr(vectorizer, 'vocabulary_'):
            st.error("Vetorizador n√£o foi treinado corretamente")
            return None
            
        return vectorizer
    except:
        try:
            # Fallback para pickle
            with open('vectorizer_thirdanalysis_new.pkl', 'rb') as f:
                vectorizer = pickle.load(f)
                
            if not hasattr(vectorizer, 'vocabulary_'):
                st.error("Vetorizador n√£o foi treinado corretamente")
                return None
                
            return vectorizer
        except Exception as e:
            st.error(f"Erro ao carregar vetorizador: {str(e)}")
            return None

# Carregamento seguro do modelo
@st.cache_resource
def load_model():
    try:
        return joblib.load('thirdanalysis_new_model.pkl')
    except:
        try:
            with open('thirdanalysis_new_model.pkl', 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            st.error(f"Erro ao carregar modelo: {str(e)}")
            return None

# Interface principal
def main():
    st.set_page_config(page_title="Analisador de Sentimentos", page_icon="üòä")
    st.title("üìù Analisador de Sentimentos em Portugu√™s")
    st.write("Digite uma avalia√ß√£o em portugu√™s para an√°lise de sentimento")

    # Carrega os componentes
    vectorizer = load_vectorizer()
    model = load_model()
    
    if vectorizer is None or model is None:
        st.error("N√£o foi poss√≠vel carregar os componentes necess√°rios")
        return

    user_input = st.text_area("Digite sua avalia√ß√£o:")
    
    if st.button("Analisar Sentimento"):
        if not user_input.strip():
            st.warning("Por favor, digite uma avalia√ß√£o.")
            return
            
        processed_text = preprocess_text(user_input)
        
        try:
            # Verifica√ß√£o final do vetorizador
            if not hasattr(vectorizer, 'transform'):
                st.error("Vetorizador n√£o est√° pronto para transforma√ß√£o")
                return
                
            text_vector = vectorizer.transform([processed_text])
            prediction = model.predict(text_vector)
            proba = model.predict_proba(text_vector)[0]
            
            st.subheader("Resultado:")
            if prediction[0] == 1:
                st.success(f"‚úÖ Positivo ({(proba[1]*100):.1f}% de confian√ßa)")
            else:
                st.error(f"‚ùå Negativo ({(proba[0]*100):.1f}% de confian√ßa)")
            
            # Visualiza√ß√£o
            prob_data = pd.DataFrame({
                'Sentimento': ['Positivo', 'Negativo'],
                'Probabilidade': [proba[1], proba[0]]
            })
            st.bar_chart(prob_data.set_index('Sentimento'))
            
        except Exception as e:
            st.error(f"Erro na an√°lise: {str(e)}")

if __name__ == "__main__":

    main()
